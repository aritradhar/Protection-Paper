\section{\name: IO Root-of-Trust}
\label{sec:systemDesign}


In this section, we provide the technical details of \name integrity protection for IO devices.  

\iffalse
\subsection{System Components}
\label{sec:systemDesign:components}

Figure~\ref{fig:approachOverview} provides the high-level approach overview of \name. The components of \name are the following:

\begin{mylist}
  \item \textbf{Host system.} The host system is completely compromised (hardware, OS and the installed applications) by the attacker.
  \item \textbf{\device.} The \device is connected to the input devices and sits between the host and the display. The \device is connected to the input devices over the \usb interface and connected to the host and the display over HDMI. Note that the \device lacks any networking capability to minimize the TCB. Additionally, the \device can emulate itself as a composite \usb device to the host.
  \item \textbf{Input device.} The input devices such as the mouse, keyboard, touchpad, etc. are connected to the \device over a \usb interface. We assume that the input devices are trusted.
  \item \textbf{Display.} The display device is connected to the \device over HDMI interface.
  \item \textbf{Remote server.} The remote server is a trusted entity that serves the web application to the host system over \http. The remote server also creates a secure channel with the \device using the host as an untrusted transport. 
  
\end{mylist}

For all these components to work in tandem, the \device and the remote server requires a communication channel. As described before, the \device does not have any networking capability. Only using the HDMI and the keyboard emulation, the \device creates a bidirectional channel with the remote server. The details of the communication channel is discussed in Section~\ref{sec:systemDesign:communicationChannel}.
\fi

\iffalse
\subsection{Initialization} 
\label{sec:systemDesign:init}

There are two steps of initialization process: 

\begin{mylist}
  \item\textbf{IO initialization.} The \device initializes the mouse by instructing the host system to move the mouse pointer to the top right corner (moving to the first right and then up for an arbitrarily large value). As the \device has access to the frames that are displayed on the screen, it can verify if the mouse pointer is at the top-right corner of the screen or not. Then it instructs the host OS to bring it to the center of the screen.
  
  \item\textbf{Network initialization.} The \device connects to the remote server using \webusb or \webbt, effectively using the host as an untrusted transport. The \device and the server establishes a secure channel with the public certificates that are distributed before-hand.
\end{mylist}
\fi


\begin{figure}[t]
\centering
\includegraphics[trim={0 13.5cm 11.5cm 0}, clip, width=\linewidth]{uiDetect_2.pdf}
\caption{\textbf{Strawman solution: Text/Image Analysis of the UIs}. This strawman solution uses image/text analysis to detect the UI element leveraging edge detection and optical character recognition (to extract the labels on the UI element). The solution suffers from lack of robustness where the \device sometime fails to correctly classify the UI elements/labels due to mouse position or colors.}
\label{fig:uiDetect}
\centering
\end{figure}

%\subsection{Output Integrity}

\subsection{Strawman solutions for IO integrity}
\label{sec:systemDesign:strawman}

Here we explain two strawman solutions by which the \device confirm that the user executes certain action, e.g., clicking a button  or selecting an option from a drop-down menu and ensures that the user views legitimate UI.

\myparagraph{Strawman solution I} In the first strawman solution, we can run an isolated operating system and browser on the \device. As the \device is trusted, we can assume that all the IO interaction is secure. But this requires to run full OS and browser on the \device making the \device as susceptible to attacks as a regular host. 

%We define \emph{\poa} as the mechanism by which the \device confirm that the user executes certain action, e.g., clicking a button  or selecting an option from a drop-down menu. 
\myparagraph{Strawman solution II} Next we explain another strawman solution that uses image/text analysis. Note that the \device sits bettween all the IO devices and the host. This enables the \device to intercept the HDMI interface. The \device takes a few snapshots of the HDMI frames when the user clicks. In Section~\ref{sec:systemDesign:analysis}, we described how the \device tracks the mouse-pointer movement across the screen preciously. As the\device precisely knows current mouse pointer, as soon as the user executes an action, e.g., clicking the mouse, the \device takes a snapshot (of area approximately $100 \times 100$ sq. px) around the mouse pointer and send the snapshot to the server using the TLS upstream channel (communication channels are discussed in Section~\ref{sec:systemDesign:communicationChannel}). Along with the snapshot, the \device also transfers the timestamp for later verification. The user input data, snapshot, and the timestamp from the \device generate the proof that the user executes certain activities. Note that, this strawman solution primarily serves as an offline audit. One use case scenario is a bank where the signed transcript can be later used to solve transaction dispute. 

This making of taking screenshot of UI elements an also be transformed into online verification by using the image and text analysis to extracts the information from the UI elemets. Such as the label on a button or the markers on a slider, etc. In Figure~\ref{fig:uiDetect} we illustrate an example scenario where the \device extract the context of the mouse position when a user clicks. This involves the \device to take a truncated screen-shot from the HDMI frame and use image analysis to understand user action. E.g., in Figure~\ref{fig:uiDetect}, \one the user first drags along the slider UI to set a value (\texttt{35}) and then \two the user clicks on the \texttt{OK}. The \device uses character recognition technique to extract the label and the data from the UI. This example shows the apparent complexity of this mechanism that does not scale with all UI. Further investigation and prototype implementation shows several drawbacks of this solution:


\begin{mylist}
  \item \textbf{Incomplete user context.} The proposed method failed to capture the complete context of the user input. Capturing the UI element only around the mouse pointer ignore the input values that are provided by the user. For example, the use may press \texttt{OK} button after providing the sensitive data, but to capture those data, the \device needs to capture more screen area. Such a method would complicate the entire process and does not generalize.
  \item \textbf{Robustness.} Previous research works such as as~\cite{lukaSpoof,Chen:2010:DVS:1754393.1754394} propose detection of a phishing attack by visually analyzing the web interface of the mobile applications. All of these proposed methods fail to achieve 100\% accuracy in the real world scenarios. Our prototype implementation also confirm that the method lacks robustness in real life as most of the time the \device fails to either recognize the UI elements or extract the label from the UI elements properly despite of using state-of-the-art image/text analysis tools~\cite{opencv}.
  \item \textbf{Performance.} The image/text analysis is CPU intensive and causes a low number of frame output by the \device. Commonly used image analysis frameworks such as OpenCV~\cite{opencv} is CPU intensive and it hard to achieve $24$ fps after the operation on the \device that is implemented on an ARM-based Raspberry Pi.
  \item \textbf{TCB.} The image/text analysis functions are needed to be implemented either on the \device or the remote server. Such increases the size of the TCB significantly.
\end{mylist}

Due to such limitations, and the inherent offline nature of this solution, we developed more efficient solution to preserve the integrity of user actions on a UI element. We describe the method in the following section. The solution has a trade-off that the developers need to incorporate some small changes to the remote server but provides better security and usability. We describe our solution in the following section.



\subsection{\device Overlay of UI Elements}
\label{sec:systemDesign:transformation}

\begin{figure*}[t]
\centering
\includegraphics[trim={0 4cm 0 0}, clip, width=0.8\linewidth]{formTransform.pdf}
\caption{\textbf{Transformation of UI elements: UI $\rightarrow$ QR code $\rightarrow$ \device generated UI overlay.} Automated transformation of the UI elements (\one) by the \name JavaScript snippets that detects the presence of the device. The corresponding \html source shows the UI elements that requires integrity/privacy protection. These UI elements are transformed into a QR code (\two). The QR code encodes a UI specification that recreates the transformed UI. Specification~\ref{snippet:UISpecification} shows the corresponding UI specification that is created by the \name \js code. The QR code is then decoded and overlaid (\three) on the HDMI stream by the \device. Upon the user's action on the overlaid UI elements, the device signs all the input data and send them to the remote server. As the rendered UI is generated and overlaid by the \device, it also ensures the integrity of the UI elements. Note that the intermediate QR code transformation (\two) is not visible by the user as it is decoded instantaneously by the device.}
\label{fig:transformation}
\end{figure*}

In the previous section, we describe the strawman solution using image/text analysis for IO integrity that has several drawbacks. In this section, we describe more efficient technique: transformation of the user interface (UI) elements.

We assume that the public certificate of the remote server is embedded into the \device. This allows the \device to verify any statement that is signed by the remote server's private key. It is also possible to establish a conventional \tls channel between the \device and the server using the HDMI channel. We provide the details how to build this \tls channel in Section~\ref{sec:systemDesign:keyEstablishment}.

This approach requires one extra component at the server side that is a Java script code snippet that we call \name JS. After the establishment of the secure channel between the \device and the remote server, the \name JS snippet that is served with the webpage transform the UI elements that requires IO integrity protection. We illustrate the method of UI transformation in Figure~\ref{fig:transformation}. The entire process has two phases: \emph{QR code generation}, and \emph{overlay of the UI}.


\lstset{language=JSON, frame=tb, caption=\textbf{Protected UI specification language.} The UI specification shows the JSON formatted UI specification that is encoded into a QR code. The specification is generated from the \html source that are tagged as protected from the developers. The example specification is generated from the \html source that is provided in corresponding UI in Figure~\ref{fig:transformation}., label=snippet:UISpecification, firstnumber =1}

\begin{figure}[t]
\begin{lstlisting}[mathescape=true]
{ "formId": "form1",
  "formName": "form1",
  "domain": "secure_site.io",
  "dim": "400*400",
  "ui": [{"id":"textbox_1",
  	"type":"textbox",
	"label":"Sensitive field 1",
	"text":"secret data 1",
	"size": 40},
	{"id":"textbox_2",
	"type":"textbox",
	"label":"Sensitive field2 ",
	"text":"secret data 2",
	"size": 40},
	{"id":"b1",
	"type":"button",
	"label":"OK",
	"trigger":"true",
	"size": 10},	
	{"id":"b2",
	"type":"button",
	"label":"Cancel",
	"trigger":"true",
	"size": 10}],
  "signature": "0x45565AB246..."}
\end{lstlisting}
\end{figure}

%%%old specification
% 
% { "formId": "form1",
%   "formName": "form1",
%   "domain": "secure-site.io"
%   "ui": [{ "id":"textbox_1",
%      "type":"textbox",
%      "label":"Sensitive field 1",
%      "text":"secret data 1"},
%    { "id":"textbox_2",
%      "type":"textbox",
%      "label":"Sensitive field 2",
%      "text":"secret data 2"},
%    {"id":"OK_button",
%      "type":"button",
%      "trigger":"true",
%      "label":"OK"},    
%    {"id":"Cancel_button",
%      "type":"button",
%      "trigger":"false",
%      "label":"Cancel"}]}
%%


\begin{mylist}
\item \textbf{QR code generation.} QR code generation phase is executed by \name JS that transforms the UI elements of a sensitive web form to a UI specification encoded in a QR code\footnote{In the prototype implementation on \name; we use QRCode.js, a \js library to produce QR codes}. UI elements that require IO integrity protection can be marked by the developers in the \html source. As illustrated in Figure~\ref{fig:transformation}, the \html UI elements: `\texttt{Sensitive field 1}' and `\texttt{Sensitive field 2}' additional attribute \texttt{protect=``true''}. The QR code generation phase is between \one and \two in Figure~\ref{fig:transformation} where the \name JavaScript snippet transforms the UI elements to a UI specification language in a QR code that can be interpreted by the \device. The UI specification corresponding to the \html source (in Figure~\ref{fig:transformation}) is provided in Specification~\ref{snippet:UISpecification}. Note that the specification is highly flexible, allowing adjustable size for the form, individual UI elements, gaps between them etc. This allows the \device to faithfully recreate the UI that is very close to the actual form UI that the served by the web severer. Such allows negligible user habituation. 

\item \textbf{Overlay.} Overlay is the next phase where the QR code that embeds the UI specification is interpreted by the \device and overlaid on the HDMI stream. The overlay faithfully recreates the UI to prevent any alteration in the user experience. The \device overlay is depicted in \three in Figure~\ref{fig:transformation}. The \device come with a small interpreter routine that converts the UI specifications to bitmaps that are then overlaid on the HDMI stream. The specification also contains the location and the size details (omitted from the Specification~\ref{snippet:UISpecification}). The \device uses this information to determine the specific UI element over which the user has her mouse pointer. As the \device parses all the HDMI frames for the QR code, the overlay does not get interrupted by scrolling.
\end{mylist}

\subsubsection{Integrity of the UI elements} Output integrity ensures the integrity of the UI elements that are sent by the remote server. As the specification sent by the server is signed (\texttt{signature} attribute in the UI specification mentioned in the Specification~\ref{snippet:UISpecification}), the \device-generated UI overlay ensure the integrity and authenticity of the UI elements on the web page. Note that the \device always draws on top of the frames that are rendered by the compromised host. This way, the overlaid UI is always visible by the user on display and the host can not manipulate the overlays.

\subsubsection{Integrity of the user input} After the UI elements are correctly overlaid on the screen, the users can interact with these UI elements. The user interaction with the overlaid UI element is no different then a standard UI, making the user habituation seamless. The UI specification encodes the behavior of all the generated UI elements, making the \device aware of the semantics of the UI objects. E.g., when a user selects a text box and types on her keyboard, the \device intercepts all the keyboard strokes and overlays the characters on the UI. When the user clicks on the \texttt{OK} button on the overlay, the device gathers all the intercepted keyboard and mouse events, signs them and send them to the remote server. One example of the proof-of-action is depicted in Figure~\ref{fig:transformation} that shows the payload that the \device sends to the server. Along with the keyboard data that is provided by the user, the \device also attaches the proof that the user indeed clicked on the \texttt{OK} button that leads to the action. Detailed description of how the input is recorded and committed is presented in Section~\ref{sec:systemDesign:commit}.


\subsubsection{Changing browser tabs or browsers}
The \device supports multiple browsing tabs across multiple browsers. The UI specification contains \texttt{formId} and \texttt{domain} that works as the unique identifier for a specific form served from a specific web server. The \device can maintain multiple parallel TLS connection to web servers. Depending on the observed \texttt{formId} and \texttt{domain} (refer to Specification~\ref{snippet:UISpecification}), the device retrieved the data that is entered by the user. This way even if the user switches tabs, the \device can still allow editing the forms across tabs. 


\subsection{Continuous Tracking of Mouse Pointer in the HDMI Frame}
\label{sec:systemDesign:analysis}


\begin{figure}[t]
\centering
\includegraphics[trim={0 5.8cm 8cm 0}, clip, width=\linewidth]{mouseAnalysis.pdf}
\caption{\textbf{Pointer integrity.} The device knows the initial pointer position by sending a high mouse value to the host that puts the pointer on a specific corner $(x_0, y_0)$. \one The \device captures the raw mouse events ($\Delta x, \Delta y$) from the mouse that is attached to the \device. \two The \device captures the frames from the HDMI channel and checks into the designated pixel position $(x_i + \Delta x, y_i + \Delta y)$ if there exists a pointer.}
\label{fig:mouseAnalysis}
\centering
\end{figure}


%\Pop is an crucial security property to understand user intention that ensures that the user is following the correct mouse pointer and all the mouse actions are actually executed by the user. 
Protecting the integrity of the mouse actions (move, drag, and click), also known as the \emph{pointer integrity} is non-trivial as one needs to know the user's context (such as the location, acceleration of the mouse pointer) on the screen. \name extracts the user context by intercepting the HDMI frames from the host system. The \device sits between the host and the display device (the monitor) and captures the HDMI frame to extract the cursor context and overlay a \device-generated mouse pointer. The overlay provides a visual cue for the user about the correct location of the mouse pointer in the case the attacker wants to trick the user by spawning multiple pointers on the screen. Pointer integrity requires two steps: detection of the pointer from the HDMI frames and overlay of the \device-generated pointer.

\subsubsection{Detection of pointer} Figure~\ref{fig:mouseAnalysis} illustrates the high-level idea of the host system's HDMI frame analysis. To match the mouse polling rate with the display frame rate, the \device only queries the input device with the frequency of $60$ Hz. We assume that over the HDMI channel the host system sends frames at the rate of $60$ fps. We define the mouse trace as the time series $(\Delta x_i = |x_{t_{i-1}} - x_{t_{i}}|, \Delta y_i=|y_{t_{i-1}} - y_{t_{i}}|)$ delta co-ordinates: $\{(\Delta x_1, \Delta y_1), (\Delta x_2, \Delta y_2), \ldots, (\Delta x_n, \Delta y_n)\}$ from time $\{t_1, t_2, \ldots, t_n\}$. $x_{t_{i}}$ and $y_{t_{i}}$ denote the pixel position of the mouse pointer on the screen at time $t_i$. At the time of initialization, i.e., the first time the \device turned on after the host boot up, the \device pushes the mouse at the left-upper corner of the screen, hence the initial mouse pointer position is set to $(x_0, y_0) = (0, 0)$.  
Note that a mouse only provides displacement of over $x$ and $y$ coordinates. This corresponds that at time $t_i$ the mouse reported $(\Delta x_i, \Delta y_i)$ displacement to the \device. Assume that the frames coming from the host system to the \device are: $\{f_1, f_2, \ldots, f_n\}$ over the same time interval $(t_1, t_2,\ldots t_n)$. At time $t_i$, the \device looks into the frame $f_i$ and draws a square centered at $(x_i, y_i)$ with sides of length $X$ (which is enough to cover a mouse cursor on the screen\footnote{in our evaluation we saw that only a 30 $\times$ 30 square px. could cover the default mouse pointer provided by Ubuntu OS.}). Then the \device checks if there exists a mouse inside this square or not. In case there exists a mouse cursor, the \device allows further user interactions; otherwise it stops all the communications and shows an error on display.

\subsubsection{Overlay of the mouse pointer} The \device draws a mouse pointer that is visible by the user. The overlaid mouse pointer is on top of the host rendered mouse pointer. The overlay provides a telltale sign to the user about the location of the mouse pointer in the case the host renders other mouse pointers on the screen to confuse the user. To emphasize the location of the mouse pointer, the \device highlights the overlaid pointer by dimming the rest of the part of the screen when there is a threshold time break (i.e., no input coming from the user for around 3 seconds).


\subsubsection{Coping with the blinking cursor} In the case the user is tying in a text editor, in some OS (e.g. Windows), the cursor starts to blink. To cope with this, the \device listens to all the keyboard input as the keyboard is also connected to the \device. Wen the \device detects there are key strokes,






\subsection{Secure Attention Sequence}
\label{sec:systemDesign:SAS}

Secure Attention Sequence (SAS) is a sequence of actions\footnote{Such as keystrokes \texttt{Ctrl+Alt+Del} that allows the user to provide her credential} executed by the user that is completely trustworthy. SAS prevents an untrusted system from triggering an event that is otherwise sensitive to the user. Note that SAS is a well-researched topic in the context of UI/UX design. \name uses off-the-shelf SAS mechanism and adapts it into the system. 

\name provides a mechanism for SAS where the user forces the \device to highlight the overlaid UI and the mouse pointer location. SAS eliminates any possibility that the attacker either i) create fake UI elsewhere in the screen that may trick the user into submitting sensitive information, or ii) spawn a fake mouse pointer to trick the user into clicking into a different location. To protect against such scenarios, \device also provides SAS using which the user can highlight the overlaid UIs and the mouse pointer on display. 
This can be activated explicitly by the user by pressing \texttt{ctrl} button.
As the \device overlays on the HDMI frames, the attacker can not manipulate any overwriting by rendering anything on top of them. 
There are to SAS mechanisms that \name employs. One is intrinsic to the user action. When the user moves her mouse, the \device briefly outlines the overlay UI. The other SAS mechanism is when the user presses a button on the \device, the \device dims the rest of the part of the display except the legitimate mouse pointer and the overlaid UIs. By doing so, the user can easily discriminate the secure UIs and the legitimate mouse pointer.

\myparagraph{Mouse pointer overlay} The mouse-pointer overlay also employs SAS. When the user press \texttt{ctrl} key on her keyboard, the \device dims all the portion of the screen except the overlaid UI and the overlaid mouse pointer. This allows the user to determine the legitimate pointer and the overlaid UI. For additional user attention, the mouse pointer also changes the out border color (\textcolor{red}{red} to \textcolor{green}{green}) when the user enters inside the overlaid UI. This also works as a indicator for the user if the browser/host impersonates a overlaid UI to trick the user into providing some security critical data.
 

\subsection{Committing User Input}
\label{sec:systemDesign:commit}

When the user finishes providing her input over the input device (mouse and keyboard), the \device commits these values to the remote server. The commitment is executed by providing the signed input values to the remote server. The commitment procedure is illustrated in Figure~\ref{fig:transformation}. The commitment has two phases: \emph{record} and \emph{commit}.

\myparagraph{Record} When user provides any information on the rendered overlay UI elements (such as textbox, button, slider, radio button, etc.), the \device records that in a (key, value) pair where the key is the identifier of the UI element (\texttt{id} in Specification~\ref{snippet:UISpecification}) and the value is the user provided value. The \texttt{type} of the UI elements determine what information to record. For example, the \device records all the keystrokes when a textbox is selected, the value corresponding to the position of the slider is recorded when the user interacts with a slider, etc. One example of the recording of the input data corresponding to the UI illustrated in Figure~\ref{fig:transformation} and Specification~\ref{snippet:UISpecification} is: 
\begin{align*}
Record = & (textbox\_1, Data\_1);(textbox\_2,Data\_2)
\end{align*}

\myparagraph{Commit} In the commitment phase, the \device waits for the user to operate on a UI element which has a \texttt{trigger} capability. For example, in Specification~\ref{snippet:UISpecification}, the \texttt{OK} and the \texttt{cancel} buttons have an attribute \texttt{trigger}. This attribute can take either \texttt{true} (corresponding to \texttt{OK}) or \texttt{false} (corresponding to \texttt{Cancel}) value that denotes that the the button can submit the values that are provided by the user or abort the form altogether. When the user performs some actions on the \texttt{trigger} enabled UI elements; the \device sends the signed, recorded value to the \name JavaScript snippet. The \name \js snippet then sends these information to the remote server by a \texttt{XMLHttpRequest} call. The commit phase also makes sure that the user moves her mouse pointer from elsewhere on the screen to the UI element using the \pop mechanism described in Section~\ref{sec:systemDesign:analysis}. Apart from clicking, the user may hit \texttt{enter} that also trigger the \device to submit the form. 


\subsection{Server-side Computation}
\label{sec:systemDesign:serverSide}

After the \device commits the input records to the remote server, the remote server verifies the input with the data that is submitted by the browser running on the compromised host. The browser sends a \http packet to the server that contains the form data submitted by the user. On the other hand, the \device sends the signed input traces from the user via the \tls channel between the \device and the remote server. The server verifies the signature and accepts the input if they are identical to the data submitted by the browser.

\begin{figure}[t]
\centering
\includegraphics[trim={0 6.5cm 12cm 0}, clip, width=\linewidth]{systemDesign.pdf}
\caption{\textbf{High level flow of \name}}
\label{fig:systemDesign}
\centering
\end{figure}

\subsection{Main Protocol}
\label{sec:systemDesign:mainProtocol}

In the previous Sections, we explain the basic components of \name. Now in this Section, we describe the flow of \name protocol. The outline of \name is illustrated in Figure~\ref{fig:systemDesign}. In the flow, we assume that the user already clicked on a web link or write on the browser link field which web application to open. The steps are the following:


\begin{mylist}
  \item[\one] The browser on the host system receives the response from the remote server. The browser renders the webpage. Note, that the webpage contains the protected UI fields that are transformed by the \name JavaScript snippet to a QR code (detailed description in Section~\ref{sec:systemDesign:transformation}). The QR code contains a UI specification that can be decoded by the \device.
  \item[\two] The graphics driver sends the rendered frame to the \device over the HDMI channel.
  \item[\three] The \device intercepts the HDMI signal and decode the QR code to retrieve the UI specification. After the decoding of the QR code, the \device renders the bitmap corresponding to the specification.
  \item[\four] The \device send the HDMI frame with the UI overlay to the display device.
  \item[\five] After observing the HDMI frame and the overlaid UI, the user passes her input to the \device via the keyboard/mouse that is connected to the \device over the \usb interface.
  \item[\six] In this step, the \device forwards mouse traces (i.e., the $(\Delta x,\Delta y)$-mouse movements along $x$ and $y$ axis) to the host system. This is achieved as the \device enumerate itself as a composite HID (that includes both keyboard and mouse) to the host. Moreover, the \device also draw an overlay of the mouse pointer on its overlaid UI as the \device draws over the HDMI frames that are generated by the host. This provides a seamless user experience (\Pop in Section~\ref{sec:systemDesign:analysis}).
  \item[\seven] When the user input her data to the host, the \device records her input data (Record phase in Section~\ref{sec:systemDesign:commit}).
  \item[\eight] The \name JavaScript snippet also acts as a upstream channel from the \device to the remote server (refer to Section~\ref{sec:systemDesign:communicationChannel}). Via this channel, the \device sends the signed user action to the remote server. This signed user action can be seen as the second factor for the integrity of the user input data. (Commit phase in Section~\ref{sec:systemDesign:commit})
  \item [\nine] The server verifies the data from the two channels that are submitted by the host and the \device. (Section~\ref{sec:systemDesign:serverSide})
\end{mylist}



\iffalse
\begin{figure}[h]
\centering
\includegraphics[trim={0 11cm 16.5cm 0}, clip, width=\linewidth]{inputPrivacy.pdf}
\caption{Input Confidentiality}
\label{fig:inputPrivacy}
\centering
\end{figure}
\fi




\subsection{Input \& Output Confidentiality}
\label{sec:systemDesign:mousePrivacy}


\begin{figure}[t]
\centering
\includegraphics[trim={0 3cm 16.5cm 0}, clip, width=0.85\linewidth]{activityPrivacyRender.pdf}
\caption{\textbf{Confidentiality of the UI and the pointer.} The figure shows how \name achieves the confidentiality of the UI elements and the mouse pointer in the presence of a compromised host. The upper screenshot shows the host's view of the display while the lower one shows the user's view. The host can only see a QR code where the specification is encrypted by the \tls session key between the \device and the remote server. The user saw the decoded and overlaid UI objects that are retrieved from the QR code sent by the remote server (as described in Section~\ref{sec:systemDesign:transformation}).}
\label{fig:activityPrivacy}
\centering
\end{figure}


\lstset{language=HTML, frame=tb, caption=\textbf{HTML page from the remote server that contains the encrypted UI specification for IO privacy.} , label = snippet:encryptedHTML, firstnumber =1}
\begin{figure}[t]
\small
\begin{lstlisting}[mathescape=true]
<form action="/some_action">
  First name:<br>
  <input type="text" name="First name">
  <br> Last name:<br>
  <input type="text" name="name">
  <encrypted>
  [QR code with encrypted specification]
  </encrypted>
  <input type="submit" value="Submit">
  <script>
  [javaScript that outputs encrypted QR code]
  </script>
</form> 
\end{lstlisting} 
\end{figure}

In the previous section (Section~\ref{sec:systemDesign:transformation}) we describe how the \name \js and the \device together transform and overlay the UI to ensure the integrity of the UI and the input data. A similar mechanism can be used to fully hide the IO to and from an attacker-controlled host. 

For input we consider two cases i) the raw input to the remote server that is provided by the user from her input device, and ii) the mouse movement which is not the direct input to the remote server but ultimately leads to sending input to the remote server. To facilitate this, the remote server sends an encrypted UI spec as shown in the HTML snippet~\ref{snippet:encryptedHTML}. The key of the encryption is the session \tls key between the remote server and the \device (detailed key exchange process is described in Section~\ref{sec:systemDesign:keyEstablishment}). The \device stops forwarding any input made by the user as soon as the user enters the overlaid area. To keep the user experience consistent, the \device also overlays  

\subsubsection{Activity Privacy}

The \name \js convert this specification to a QR code that is intercepted, decoded and decrypted by the \device. The overall flow of the system is shown in Figure~\ref{fig:activityPrivacy}. When the user enters her mouse pointer into the overlaid UI boundary, the \device stops transmitting any mouse data to the host system, making the host completely oblivious to any mouse movement done by the user. Likewise when the user selects a UI element, for example a radio button that is shown in Figure~\ref{fig:activityPrivacy},the \device directly sends the commands to the remote server making the input commands/values hidden from the attacker-controlled host.  


\subsection{Communication Channel}
\label{sec:systemDesign:communicationChannel}

The communication channel between the \device and the remote server is constructed without employing any and separate hardware/software or web-browser extensions. \name two-way communication works out-of-the-box using JavaScript code and QR code decoding routine that runs on the \device. The \emph{downstream} channel, i.e., the data channel from the remote server and the \device relies on the HDMI channel. The remote server encodes the information in the webpage in QR code that is intercepted by the \device from the HDMI channel and decoded.

The \emph{upstream} channel, i.e., the data from the \device to the remote server is transmitted using the \name JavaScript snippet that is served by the remote web server. The \name JavaScript snippet uses a hidden text field to accept data coming from the \device. The \device emulates itself as a composite keyboard-mouse device when it is connected to the host. The \device emulates keystrokes that transmit encoded data to the \name JavaScript snippet that is sent to the remote server via \texttt{XMLHttpRequest} call.

One instance of the communication channel is depicted in Figure~\ref{fig:keyExchange} that is used to establish a \tls channel between the \device and the remote server. The following section provides a detailed description of the key establishment protocol.

\subsection{Key Establishment Protocol}
\label{sec:systemDesign:keyEstablishment}

\begin{figure}[t]
\centering
\includegraphics[trim={0 8cm 18cm 0}, clip, width=0.8\linewidth]{keyExchange.pdf}
\caption{\textbf{Key establishment.} A snapshot of the key exchange web page that is used to communicate the public certificates of the device and the remote server. This page only lasts for a few milliseconds. Hence the page is practically invisible to the user. The QR-code displayed on the web page serves as the downstream channel from the remote server to the \device, whereas the text field is the upstream channel.}
\label{fig:keyExchange}
\centering
\end{figure}


When the user opens up a webpage that supports \name mechanism, key exchange is the first step that is executed by the \device. Also, the key exchange phase is crucial as the remote server also access if the user has a \device. An instance of the key exchange mechanism of \name is illustrated in Figure~\ref{fig:keyExchange}. The flow of the key exchange mechanism is as the following:

\begin{mylist}
  \item The remote web server serves the web page that shows a QR code that encodes the signed public key of the remote server (server hello in TLS). This page has a $5$ seconds timeout.
  \item The device captures the frames and looks for a QR code. As soon as the device finds one, the device decodes the QR code and verifies it.
  \item If the verification is successful, the device emulates itself as a keyboard device to the host system. The device then encodes its signed public certificate to hexadecimal and send it as a keystroke to the host (client hello in the TLS). For signature, the \device uses the root key of the device manufacturer.
  \item The \name  JavaScript snippet looks for the keystrokes, and as soon as it gets a string of a specific length, it sends the key strokes to the remote server, and the \name JavaScripts loads the webpage.
  \item In case the user does not have a \device, the step mentioned above does not take place within the $5$ seconds timeout period. In that case, \name JavaScript snippet concludes that the user does not have a \device. This allows the webpage to fallback to conventional web UIs that does not involve \device fro their operation.
\end{mylist}

After this, both the device and the remote server have each other's public certificates. Using these certificates, both the \device and remote server calculates the shared secret using the authenticated Diffie-Hellman protocol~\footnote{Assume that $(g^x, x)$ and $(g^y, y)$ being the public-private key pair of the remote server and the \device respectively, where $g$ being a generator of a group $G$. The remote server sends a QR code that encodes a CA-signed $g^x$. The \device transmits signed $g^y$ to the remote server. Both the remote server and the \device computes $g^{xy}$ as the shared secret. Detailed description can be found  in~\cite{blake1998authenticated}.}.
